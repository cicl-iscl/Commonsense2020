{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ALLRIGHT METHOD TIME\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Method to get the data\n",
    "Requires at least one path/url as string and a name for the to be loaded data\n",
    "\n",
    "Returns a dict with name of data as key and loaded data as DataFrame as value.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_data_from_urls(path, name, path_2=None, name_2=None):\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    data_dict[name] = data\n",
    "    \n",
    "    if path_2:\n",
    "        data_2 = pd.read_csv(path_2, index_col=0)\n",
    "        \n",
    "        data_dict[name_2] = data_2\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Test get_data_from_urls\n",
    "#####\n",
    "url_data_task_A = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_data_all.csv\"\n",
    "url_answers_task_A = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_answers_all.csv\"\n",
    "\n",
    "data = get_data_from_urls(url_data_task_A, 'data_a', url_answers_task_A, 'answers_a')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to get different words\n",
    "Uses spacy tokenizer instead of bert\n",
    "Takes a tuple of string sentences and a parser\n",
    "\n",
    "Returns tuple of dicts with different words as keys, index of word in sentence as value\n",
    "alternatively the dep tags of the different words if return_dep=True\n",
    "\n",
    "Helper-Method to get spacy parser\n",
    "takes a name of language model (?) as string\n",
    "returns parser\n",
    "\"\"\"\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_different_words(sent_tuple, parser, return_dep=False):\n",
    "\n",
    "    sen_0 = parser(sent_tuple[0])\n",
    "    sen_1 = parser(sent_tuple[1])\n",
    "\n",
    "    length_0 = len(sen_0)\n",
    "    length_1 = len(sen_1)\n",
    "\n",
    "    differ_dict_0 = {}\n",
    "    differ_dict_1 = {}\n",
    "\n",
    "    index_of_word = 0\n",
    "\n",
    "    for token in sen_0:\n",
    "        word = token.text\n",
    "        dep_tag = token.dep_\n",
    "        if not word in sen_1.text:\n",
    "            if return_dep:\n",
    "                differ_dict_0[word] = dep_tag\n",
    "            else:\n",
    "                differ_dict_0[word] = index_of_word\n",
    "            \n",
    "            index_of_word += 1\n",
    "        else:\n",
    "            index_of_word += 1\n",
    "\n",
    "    index_of_word = 0\n",
    "    for token in sen_1:\n",
    "        word = token.text\n",
    "        dep_tag = token.dep_\n",
    "        if not word in sen_0.text:\n",
    "            if return_dep:\n",
    "                differ_dict_1[word] = dep_tag\n",
    "            else:\n",
    "                differ_dict_1[word] = index_of_word\n",
    "            \n",
    "            index_of_word += 1\n",
    "        else:\n",
    "            index_of_word += 1\n",
    "\n",
    "\n",
    "    differ_dict = (differ_dict_0, differ_dict_1)\n",
    "    \n",
    "    return differ_dict\n",
    "\n",
    "def get_parser(model_name):\n",
    "    \n",
    "    try:\n",
    "        parser = spacy.load(model_name)\n",
    "        return parser\n",
    "    except:\n",
    "        !python3 -m spacy download model_name\n",
    "\n",
    "        try:\n",
    "            parser = spacy.load(model_name)\n",
    "            return parser\n",
    "        except:\n",
    "            print('Something went horribly wrong. Check your model')\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "sent_tuple = ('I lol the elephant into the fridge',\n",
    "                 'I put the turkey into the fridge')\n",
    "different_words = get_different_words(sent_tuple, parser, return_dep=False)\n",
    "\n",
    "for key, value in different_words[0].items():\n",
    "    print(type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"getting different words and dep_tags for small analysis\"\"\"\n",
    "different_words = []\n",
    "\n",
    "for idx, row in data['data_a'].iterrows():\n",
    "    different_words.append(get_different_words((row[0],row[1]),parser,return_dep=True))\n",
    "    #print(different_words)\n",
    "    #break\n",
    "print(len(different_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quantmod': 0,\n",
       " 'csubjpass': 0,\n",
       " 'preconj': 1,\n",
       " 'intj': 3,\n",
       " 'nmod': 4,\n",
       " 'expl': 5,\n",
       " 'agent': 9,\n",
       " 'dative': 12,\n",
       " 'predet': 13,\n",
       " 'appos': 15,\n",
       " 'dep': 23,\n",
       " 'oprd': 38,\n",
       " 'acl': 40,\n",
       " 'case': 42,\n",
       " 'csubj': 55,\n",
       " 'auxpass': 64,\n",
       " 'mark': 71,\n",
       " 'cc': 86,\n",
       " 'npadvmod': 95,\n",
       " 'relcl': 113,\n",
       " 'prt': 157,\n",
       " 'pcomp': 189,\n",
       " 'nummod': 197,\n",
       " 'ccomp': 203,\n",
       " 'nsubjpass': 282,\n",
       " 'conj': 304,\n",
       " 'poss': 331,\n",
       " 'neg': 395,\n",
       " 'advcl': 404,\n",
       " 'punct': 425,\n",
       " 'xcomp': 427,\n",
       " 'aux': 503,\n",
       " 'advmod': 541,\n",
       " 'attr': 643,\n",
       " 'det': 900,\n",
       " 'prep': 1113,\n",
       " 'acomp': 1128,\n",
       " 'compound': 1251,\n",
       " 'amod': 1266,\n",
       " 'ROOT': 2121,\n",
       " 'nsubj': 2876,\n",
       " 'pobj': 5437,\n",
       " 'dobj': 5475}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_occ = {}\n",
    "for dic in different_words:\n",
    "    for sent in dic:\n",
    "        for key, value in sent.items():\n",
    "            #print(value)\n",
    "            if value in count_occ:\n",
    "                count_occ[value] += 1\n",
    "            else: count_occ[value] = 0\n",
    "\n",
    "{k: v for k, v in sorted(count_occ.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to get dependents of subj/objs with or without verb\n",
    "takes a parser, different subj or obj and its index, corresponding sentence, boolean with verb\n",
    "\n",
    "returns list of dependents\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"BEWARE: DIFFERENT INDIRECT OBJECTS REQUIRE SEPARATE METHOD\"\"\"\n",
    "\"\"\"this approach maybe doesnt even make sense...damn, \n",
    "maybe we should just throw out the stopwords and then calculate similarities\"\"\"\n",
    "\n",
    "#def get_subj_obj_dependents(parser, different_word, index sentence, with_verb=False):\n",
    "parser = parser\n",
    "different_word = 'elephant'\n",
    "index = different_words[0][different_word]\n",
    "sentence = sent_tuple[0]\n",
    "with_verb = False\n",
    "\n",
    "parse = parser(sentence) \n",
    "verb_dependents = []\n",
    "\n",
    "parent = parse[index].head\n",
    "\n",
    "if parent.pos_ == 'VERB':\n",
    "    # now we want all children of the verb with subj and obj labels\n",
    "\n",
    "    for child in parent.children:\n",
    "        if child.dep_[-2:] == 'bj':\n",
    "            verb_dependents.append(child)\n",
    "        else:\n",
    "            for nephew in child.children:\n",
    "                if nephew.dep_[-2:] == 'bj':\n",
    "                    verb_dependents.append(nephew)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, elephant, fridge]\n"
     ]
    }
   ],
   "source": [
    "print(verb_dependents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10000, 30, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = np.load('single_word_embs.npy')\n",
    "loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
