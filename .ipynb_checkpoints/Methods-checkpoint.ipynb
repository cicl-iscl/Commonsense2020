{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ALLRIGHT METHOD TIME\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Method to get the data\n",
    "Requires at least one path/url as string and a name for the to be loaded data\n",
    "\n",
    "Returns a dict with name of data as key and loaded data as DataFrame as value.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_data_from_urls(path, name, path_2=None, name_2=None):\n",
    "    \n",
    "    data_dict = {}\n",
    "    \n",
    "    data = pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    data_dict[name] = data\n",
    "    \n",
    "    if path_2:\n",
    "        data_2 = pd.read_csv(path_2, index_col=0)\n",
    "        \n",
    "        data_dict[name_2] = data_2\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Test get_data_from_urls\n",
    "#####\n",
    "url_data_task_A = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_data_all.csv\"\n",
    "url_answers_task_A = \"https://raw.githubusercontent.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation/master/Training%20%20Data/subtaskA_answers_all.csv\"\n",
    "\n",
    "data = get_data_from_urls(url_data_task_A, 'data_a', url_answers_task_A, 'answers_a')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to get different words\n",
    "Uses spacy tokenizer instead of bert\n",
    "Takes a tuple of string sentences and a parser\n",
    "\n",
    "Returns a dict with different words as keys, index of word in sentence as value\n",
    "\n",
    "Helper-Method to get spacy parser\n",
    "takes a name of language model (?) as string\n",
    "returns parser\n",
    "\"\"\"\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_different_words(sent_tuple, parser):\n",
    "\n",
    "    sen_0 = parser(sent_tuple[0])\n",
    "    sen_1 = parser(sent_tuple[1])\n",
    "\n",
    "    length_0 = len(sen_0)\n",
    "    length_1 = len(sen_1)\n",
    "\n",
    "    differ_dict_0 = {}\n",
    "    differ_dict_1 = {}\n",
    "\n",
    "    index_of_word = 0\n",
    "\n",
    "    for token in sen_0:\n",
    "        word = token.text\n",
    "\n",
    "        if not word in sen_1.text:\n",
    "            differ_dict_0[word] = index_of_word\n",
    "            index_of_word += 1\n",
    "        else:\n",
    "            index_of_word += 1\n",
    "\n",
    "    index_of_word = 0\n",
    "    for token in sen_1:\n",
    "        word = token.text\n",
    "\n",
    "        if not word in sen_0.text:\n",
    "            differ_dict_1[word] = index_of_word\n",
    "            index_of_word += 1\n",
    "        else:\n",
    "            index_of_word += 1\n",
    "\n",
    "\n",
    "    differ_dict = (differ_dict_0, differ_dict_1)\n",
    "    \n",
    "    return differ_dict\n",
    "\n",
    "def get_parser(model_name):\n",
    "    \n",
    "    try:\n",
    "        parser = spacy.load(model_name)\n",
    "        return parser\n",
    "    except:\n",
    "        !python3 -m spacy download model_name\n",
    "\n",
    "        try:\n",
    "            parser = spacy.load(model_name)\n",
    "            return parser\n",
    "        except:\n",
    "            print('Something went horribly wrong. Check your model')\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "sent_tuple = ('I lol the elephant into the fridge',\n",
    "                 'I put the turkey into the fridge')\n",
    "different_words = get_different_words(sent_tuple, parser)\n",
    "\n",
    "for key, value in different_words[0].items():\n",
    "    print(type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method to get dependents of subj/objs with or without verb\n",
    "takes a parser, different subj or obj and its index, corresponding sentence, boolean with verb\n",
    "\n",
    "returns list of dependents\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"BEWARE: DIFFERENT INDIRECT OBJECTS REQUIRE SEPARATE METHOD\"\"\"\n",
    "\"\"\"this approach maybe doesnt even make sense...damn, \n",
    "maybe we should just throw out the stopwords and then calculate similarities\"\"\"\n",
    "\n",
    "#def get_subj_obj_dependents(parser, different_word, index sentence, with_verb=False):\n",
    "parser = parser\n",
    "different_word = 'elephant'\n",
    "index = different_words[0][different_word]\n",
    "sentence = sent_tuple[0]\n",
    "with_verb = False\n",
    "\n",
    "parse = parser(sentence) \n",
    "verb_dependents = []\n",
    "\n",
    "parent = parse[index].head\n",
    "\n",
    "if parent.pos_ == 'VERB':\n",
    "    # now we want all children of the verb with subj and obj labels\n",
    "\n",
    "    for child in parent.children:\n",
    "        if child.dep_[-2:] == 'bj':\n",
    "            verb_dependents.append(child)\n",
    "        else:\n",
    "            for nephew in child.children:\n",
    "                if nephew.dep_[-2:] == 'bj':\n",
    "                    verb_dependents.append(nephew)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, elephant, fridge]\n"
     ]
    }
   ],
   "source": [
    "print(verb_dependents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"compute similarity for all right predictions and take average, if novel sentence have similarity below this average\n",
    "use perplexity rather\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
